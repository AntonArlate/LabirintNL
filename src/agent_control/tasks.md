1. Необходимо создать нейросеть. Для начала простую. Которая бы считывал значения и выдавала обработанный результат.
2. Создать функцию генерации ошибки. Попытаться повторить алгоритм q-learning. Вероятное правило должно выглядеть так: 

    * Нейросеть считает ожидаемую награду за действия и выбирает необходимое. 
    * Среда выполняет действие.
    * Генератор ошибки считывает полученную награду и сравнивает с прогнозом. Отправляет разницу на обучение сети с прошлым решением.

3. Прогнозирование возможных проблем и заметки по устранению.
    * Можно попробовать считать не сумму наград, а награду за текущий шаг.
    * Чтобы заставить более активно двигаться и искать решения возможно потребуется что-то типо голода. Тоесть растущий со временем штраф.
    * Скорей всего очень вероятна проблема “залипания” в тупиках. Можно попробовать рекурентно подать решение одного из слоёв. Однако всёравно после одного шага назад нейросеть вернётся в тупик так как продолжать движение назад менее выгодно. Человек при попадании на развилку запомнит её, а при попадании в тупик получит стимул вернуться к развилке. Ещё вариант придумать стимул к исследованию, тогда всёравно потребуется некая память. Есть ли возможность создать такую сеть которая будет сходиться на переданную координату добавляя что-то вроде “известности” и двигаться в наименее изученную сторону. Стоит ли продумать алгоритм “забывания”.

15.04.2024
    Попробовал реализовать базовую нейросеть с использованием библиотеки numpy. Хотелось бы использовать библиотеки машинного обучения, но пока не удаётся разобраться.
